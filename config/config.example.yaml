# PS Agents Configuration

# Server Configuration
server:
  host: "0.0.0.0"
  port: 8080
  grpc_port: 50051

# Pipeline Configuration
pipeline:
  batch_size: 100
  max_workers: 4
  timeout: "30s"

devmode:
  enabled: true
  max_messages: 10

# Graph Database Configuration
graphdb:
  type: "neo4j"  # or "janusgraph"
  host: "localhost"
  port: 7687
  username: "neo4j"
  password: "password"
  similarity_anchors: 2   # see README.md for more details
  semantic_frontier: 2    # see README.md for more details

# Embeddings Configuration
# Supports local Qdrant vector database storage
qdrant:
  enabled: true
  path: "data/qdrant"  # Local file path for Qdrant storage
  collection_name: "embeddings"
  vector_size: 1024
  distance: "Cosine"  # Options: Cosine, Euclid, Dot
  on_disk_payload: true  # Store payload on disk to reduce memory usage
  optimize_for_disk_access: true  # Optimize for disk access patterns

embeddings:
  model: "mxbai-embed-large"
  dimension: 1024
  cache_size: 1000
  similarity_threshold: 0.8
  endpoint: "http://localhost:11434/api/embeddings"  # Separate embedding endpoint

# LLM Configuration
llm:
  provider: "ollama"
  endpoint: "http://localhost:11434/api/chat"  # LLM-specific endpoint
  timeout_seconds: 30
  model: "gpt-4"
  api_key: "${OPENAI_API_KEY}"
  max_tokens: 1000
  temperature: 0.7
  llm_threshold:
    min: 0.3
    max: 0.8

# Data Configuration
data:
  input_dir: "data/input"
  output_dir: "data/output"
  temp_dir: "data/temp"

# Logging Configuration
logging:
  level: "info"
  format: "json"
  output: "logs/app.log"